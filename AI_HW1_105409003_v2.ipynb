{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_HW1_105409003_v2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rQ15obp4gFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-l8cBpx4mA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EBgV1Ho4l-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikUai_vP4l5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhblquRA4l2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), \n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUazx0OP4lo5",
        "colab_type": "code",
        "outputId": "fdc03f56-9df4-47a4-bb4f-a26f73a81873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZGlsdhz4zvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Y5HNMd4zoa",
        "colab_type": "code",
        "outputId": "cf45949b-a250-4e19-d893-f311a36b7452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training\n",
        "batch_size = 64\n",
        "epochs=100\n",
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep75.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 1.9470 - accuracy: 0.4269 - val_loss: 1.3312 - val_accuracy: 0.5820\n",
            "Epoch 2/300\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 1.3848 - accuracy: 0.5827 - val_loss: 1.0299 - val_accuracy: 0.6719\n",
            "Epoch 3/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 1.1635 - accuracy: 0.6436 - val_loss: 1.0732 - val_accuracy: 0.6845\n",
            "Epoch 4/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 1.0419 - accuracy: 0.6792 - val_loss: 0.9009 - val_accuracy: 0.7316\n",
            "Epoch 5/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.9607 - accuracy: 0.7058 - val_loss: 0.8773 - val_accuracy: 0.7429\n",
            "Epoch 6/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.9007 - accuracy: 0.7258 - val_loss: 0.7868 - val_accuracy: 0.7686\n",
            "Epoch 7/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.8624 - accuracy: 0.7410 - val_loss: 0.8013 - val_accuracy: 0.7765\n",
            "Epoch 8/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.8261 - accuracy: 0.7531 - val_loss: 0.7350 - val_accuracy: 0.7932\n",
            "Epoch 9/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.8053 - accuracy: 0.7635 - val_loss: 0.7734 - val_accuracy: 0.7847\n",
            "Epoch 10/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7848 - accuracy: 0.7702 - val_loss: 0.8698 - val_accuracy: 0.7518\n",
            "Epoch 11/300\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7633 - accuracy: 0.7776 - val_loss: 0.8425 - val_accuracy: 0.7661\n",
            "Epoch 12/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7503 - accuracy: 0.7834 - val_loss: 0.7185 - val_accuracy: 0.8006\n",
            "Epoch 13/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7343 - accuracy: 0.7890 - val_loss: 0.7359 - val_accuracy: 0.8025\n",
            "Epoch 14/300\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7247 - accuracy: 0.7941 - val_loss: 0.6602 - val_accuracy: 0.8180\n",
            "Epoch 15/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7157 - accuracy: 0.7970 - val_loss: 0.7133 - val_accuracy: 0.8096\n",
            "Epoch 16/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7035 - accuracy: 0.8043 - val_loss: 0.6627 - val_accuracy: 0.8217\n",
            "Epoch 17/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7020 - accuracy: 0.8029 - val_loss: 0.7047 - val_accuracy: 0.8111\n",
            "Epoch 18/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6871 - accuracy: 0.8090 - val_loss: 0.6790 - val_accuracy: 0.8162\n",
            "Epoch 19/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6829 - accuracy: 0.8109 - val_loss: 0.6682 - val_accuracy: 0.8266\n",
            "Epoch 20/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6791 - accuracy: 0.8139 - val_loss: 0.6601 - val_accuracy: 0.8263\n",
            "Epoch 21/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6696 - accuracy: 0.8163 - val_loss: 0.5982 - val_accuracy: 0.8467\n",
            "Epoch 22/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6619 - accuracy: 0.8212 - val_loss: 0.6513 - val_accuracy: 0.8320\n",
            "Epoch 23/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6625 - accuracy: 0.8193 - val_loss: 0.6238 - val_accuracy: 0.8420\n",
            "Epoch 24/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6563 - accuracy: 0.8228 - val_loss: 0.6445 - val_accuracy: 0.8324\n",
            "Epoch 25/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6457 - accuracy: 0.8265 - val_loss: 0.6570 - val_accuracy: 0.8312\n",
            "Epoch 26/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6467 - accuracy: 0.8261 - val_loss: 0.6791 - val_accuracy: 0.8219\n",
            "Epoch 27/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6442 - accuracy: 0.8284 - val_loss: 0.6249 - val_accuracy: 0.8397\n",
            "Epoch 28/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6402 - accuracy: 0.8287 - val_loss: 0.6961 - val_accuracy: 0.8246\n",
            "Epoch 29/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6333 - accuracy: 0.8318 - val_loss: 0.6251 - val_accuracy: 0.8405\n",
            "Epoch 30/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6357 - accuracy: 0.8309 - val_loss: 0.7821 - val_accuracy: 0.8049\n",
            "Epoch 31/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6272 - accuracy: 0.8336 - val_loss: 0.6225 - val_accuracy: 0.8405\n",
            "Epoch 32/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6343 - accuracy: 0.8335 - val_loss: 0.5983 - val_accuracy: 0.8511\n",
            "Epoch 33/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6262 - accuracy: 0.8328 - val_loss: 0.6134 - val_accuracy: 0.8456\n",
            "Epoch 34/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6247 - accuracy: 0.8369 - val_loss: 0.5878 - val_accuracy: 0.8516\n",
            "Epoch 35/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6227 - accuracy: 0.8370 - val_loss: 0.6923 - val_accuracy: 0.8270\n",
            "Epoch 36/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6218 - accuracy: 0.8368 - val_loss: 0.5856 - val_accuracy: 0.8527\n",
            "Epoch 37/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6173 - accuracy: 0.8386 - val_loss: 0.5981 - val_accuracy: 0.8503\n",
            "Epoch 38/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6199 - accuracy: 0.8370 - val_loss: 0.6302 - val_accuracy: 0.8398\n",
            "Epoch 39/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6161 - accuracy: 0.8386 - val_loss: 0.6610 - val_accuracy: 0.8328\n",
            "Epoch 40/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6137 - accuracy: 0.8412 - val_loss: 0.5976 - val_accuracy: 0.8531\n",
            "Epoch 41/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6116 - accuracy: 0.8418 - val_loss: 0.6178 - val_accuracy: 0.8462\n",
            "Epoch 42/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6110 - accuracy: 0.8419 - val_loss: 0.6240 - val_accuracy: 0.8458\n",
            "Epoch 43/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6077 - accuracy: 0.8432 - val_loss: 0.5671 - val_accuracy: 0.8605\n",
            "Epoch 44/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6034 - accuracy: 0.8431 - val_loss: 0.6081 - val_accuracy: 0.8458\n",
            "Epoch 45/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6032 - accuracy: 0.8446 - val_loss: 0.6220 - val_accuracy: 0.8461\n",
            "Epoch 46/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6043 - accuracy: 0.8449 - val_loss: 0.6311 - val_accuracy: 0.8463\n",
            "Epoch 47/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6018 - accuracy: 0.8450 - val_loss: 0.6411 - val_accuracy: 0.8413\n",
            "Epoch 48/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.6001 - accuracy: 0.8462 - val_loss: 0.6292 - val_accuracy: 0.8389\n",
            "Epoch 49/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6009 - accuracy: 0.8449 - val_loss: 0.6196 - val_accuracy: 0.8464\n",
            "Epoch 50/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5996 - accuracy: 0.8470 - val_loss: 0.5828 - val_accuracy: 0.8624\n",
            "Epoch 51/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5979 - accuracy: 0.8487 - val_loss: 0.6218 - val_accuracy: 0.8454\n",
            "Epoch 52/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5985 - accuracy: 0.8450 - val_loss: 0.6012 - val_accuracy: 0.8517\n",
            "Epoch 53/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5993 - accuracy: 0.8461 - val_loss: 0.6385 - val_accuracy: 0.8392\n",
            "Epoch 54/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5920 - accuracy: 0.8489 - val_loss: 0.6047 - val_accuracy: 0.8491\n",
            "Epoch 55/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5963 - accuracy: 0.8482 - val_loss: 0.6690 - val_accuracy: 0.8317\n",
            "Epoch 56/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5891 - accuracy: 0.8504 - val_loss: 0.5391 - val_accuracy: 0.8711\n",
            "Epoch 57/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5939 - accuracy: 0.8488 - val_loss: 0.6092 - val_accuracy: 0.8490\n",
            "Epoch 58/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5884 - accuracy: 0.8516 - val_loss: 0.5801 - val_accuracy: 0.8596\n",
            "Epoch 59/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5859 - accuracy: 0.8518 - val_loss: 0.5572 - val_accuracy: 0.8682\n",
            "Epoch 60/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5889 - accuracy: 0.8492 - val_loss: 0.5855 - val_accuracy: 0.8599\n",
            "Epoch 61/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5857 - accuracy: 0.8524 - val_loss: 0.5280 - val_accuracy: 0.8812\n",
            "Epoch 62/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5845 - accuracy: 0.8503 - val_loss: 0.5789 - val_accuracy: 0.8572\n",
            "Epoch 63/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5925 - accuracy: 0.8486 - val_loss: 0.5872 - val_accuracy: 0.8614\n",
            "Epoch 64/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5857 - accuracy: 0.8506 - val_loss: 0.5671 - val_accuracy: 0.8630\n",
            "Epoch 65/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5803 - accuracy: 0.8536 - val_loss: 0.5744 - val_accuracy: 0.8630\n",
            "Epoch 66/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5848 - accuracy: 0.8528 - val_loss: 0.6344 - val_accuracy: 0.8412\n",
            "Epoch 67/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5824 - accuracy: 0.8532 - val_loss: 0.6408 - val_accuracy: 0.8410\n",
            "Epoch 68/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5819 - accuracy: 0.8535 - val_loss: 0.6001 - val_accuracy: 0.8560\n",
            "Epoch 69/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5864 - accuracy: 0.8523 - val_loss: 0.5358 - val_accuracy: 0.8744\n",
            "Epoch 70/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5783 - accuracy: 0.8546 - val_loss: 0.6003 - val_accuracy: 0.8587\n",
            "Epoch 71/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5835 - accuracy: 0.8530 - val_loss: 0.6131 - val_accuracy: 0.8540\n",
            "Epoch 72/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5824 - accuracy: 0.8532 - val_loss: 0.6038 - val_accuracy: 0.8564\n",
            "Epoch 73/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5779 - accuracy: 0.8560 - val_loss: 0.5515 - val_accuracy: 0.8708\n",
            "Epoch 74/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5783 - accuracy: 0.8563 - val_loss: 0.5842 - val_accuracy: 0.8635\n",
            "Epoch 75/300\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5790 - accuracy: 0.8553 - val_loss: 0.5944 - val_accuracy: 0.8589\n",
            "Epoch 76/300\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.5786 - accuracy: 0.8541 - val_loss: 0.6120 - val_accuracy: 0.8558\n",
            "Epoch 77/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5806 - accuracy: 0.8527 - val_loss: 0.6175 - val_accuracy: 0.8500\n",
            "Epoch 78/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5781 - accuracy: 0.8554 - val_loss: 0.6091 - val_accuracy: 0.8517\n",
            "Epoch 79/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5750 - accuracy: 0.8554 - val_loss: 0.5910 - val_accuracy: 0.8581\n",
            "Epoch 80/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5791 - accuracy: 0.8561 - val_loss: 0.6499 - val_accuracy: 0.8417\n",
            "Epoch 81/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5683 - accuracy: 0.8587 - val_loss: 0.5408 - val_accuracy: 0.8772\n",
            "Epoch 82/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5742 - accuracy: 0.8554 - val_loss: 0.5659 - val_accuracy: 0.8665\n",
            "Epoch 83/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5725 - accuracy: 0.8569 - val_loss: 0.5729 - val_accuracy: 0.8618\n",
            "Epoch 84/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5717 - accuracy: 0.8575 - val_loss: 0.6157 - val_accuracy: 0.8541\n",
            "Epoch 85/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5733 - accuracy: 0.8553 - val_loss: 0.6863 - val_accuracy: 0.8325\n",
            "Epoch 86/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5697 - accuracy: 0.8572 - val_loss: 0.6426 - val_accuracy: 0.8449\n",
            "Epoch 87/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5694 - accuracy: 0.8569 - val_loss: 0.5336 - val_accuracy: 0.8781\n",
            "Epoch 88/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5646 - accuracy: 0.8609 - val_loss: 0.5929 - val_accuracy: 0.8563\n",
            "Epoch 89/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5624 - accuracy: 0.8606 - val_loss: 0.5816 - val_accuracy: 0.8633\n",
            "Epoch 90/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5627 - accuracy: 0.8616 - val_loss: 0.6207 - val_accuracy: 0.8529\n",
            "Epoch 91/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5778 - accuracy: 0.8547 - val_loss: 0.6441 - val_accuracy: 0.8446\n",
            "Epoch 92/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5639 - accuracy: 0.8596 - val_loss: 0.5920 - val_accuracy: 0.8626\n",
            "Epoch 93/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5656 - accuracy: 0.8597 - val_loss: 0.6192 - val_accuracy: 0.8504\n",
            "Epoch 94/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5680 - accuracy: 0.8586 - val_loss: 0.6020 - val_accuracy: 0.8590\n",
            "Epoch 95/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5696 - accuracy: 0.8556 - val_loss: 0.6260 - val_accuracy: 0.8436\n",
            "Epoch 96/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5665 - accuracy: 0.8598 - val_loss: 0.5648 - val_accuracy: 0.8671\n",
            "Epoch 97/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5683 - accuracy: 0.8587 - val_loss: 0.5732 - val_accuracy: 0.8662\n",
            "Epoch 98/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5610 - accuracy: 0.8596 - val_loss: 0.5909 - val_accuracy: 0.8604\n",
            "Epoch 99/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5658 - accuracy: 0.8600 - val_loss: 0.6074 - val_accuracy: 0.8539\n",
            "Epoch 100/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5624 - accuracy: 0.8592 - val_loss: 0.5742 - val_accuracy: 0.8612\n",
            "Epoch 101/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5632 - accuracy: 0.8592 - val_loss: 0.5466 - val_accuracy: 0.8750\n",
            "Epoch 102/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5623 - accuracy: 0.8602 - val_loss: 0.5687 - val_accuracy: 0.8637\n",
            "Epoch 103/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5623 - accuracy: 0.8607 - val_loss: 0.6241 - val_accuracy: 0.8458\n",
            "Epoch 104/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5639 - accuracy: 0.8597 - val_loss: 0.5628 - val_accuracy: 0.8676\n",
            "Epoch 105/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5640 - accuracy: 0.8599 - val_loss: 0.5596 - val_accuracy: 0.8691\n",
            "Epoch 106/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5637 - accuracy: 0.8605 - val_loss: 0.6722 - val_accuracy: 0.8339\n",
            "Epoch 107/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5633 - accuracy: 0.8609 - val_loss: 0.5367 - val_accuracy: 0.8720\n",
            "Epoch 108/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5638 - accuracy: 0.8583 - val_loss: 0.5882 - val_accuracy: 0.8583\n",
            "Epoch 109/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5578 - accuracy: 0.8627 - val_loss: 0.5977 - val_accuracy: 0.8595\n",
            "Epoch 110/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5598 - accuracy: 0.8623 - val_loss: 0.6702 - val_accuracy: 0.8415\n",
            "Epoch 111/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5598 - accuracy: 0.8611 - val_loss: 0.5390 - val_accuracy: 0.8748\n",
            "Epoch 112/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5561 - accuracy: 0.8633 - val_loss: 0.5395 - val_accuracy: 0.8720\n",
            "Epoch 113/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5594 - accuracy: 0.8590 - val_loss: 0.6704 - val_accuracy: 0.8369\n",
            "Epoch 114/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5583 - accuracy: 0.8615 - val_loss: 0.5802 - val_accuracy: 0.8640\n",
            "Epoch 115/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5634 - accuracy: 0.8590 - val_loss: 0.6640 - val_accuracy: 0.8419\n",
            "Epoch 116/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5571 - accuracy: 0.8629 - val_loss: 0.6036 - val_accuracy: 0.8556\n",
            "Epoch 117/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5537 - accuracy: 0.8632 - val_loss: 0.5361 - val_accuracy: 0.8767\n",
            "Epoch 118/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5562 - accuracy: 0.8615 - val_loss: 0.6292 - val_accuracy: 0.8457\n",
            "Epoch 119/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5533 - accuracy: 0.8632 - val_loss: 0.5735 - val_accuracy: 0.8666\n",
            "Epoch 120/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5585 - accuracy: 0.8624 - val_loss: 0.6574 - val_accuracy: 0.8446\n",
            "Epoch 121/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5567 - accuracy: 0.8617 - val_loss: 0.5655 - val_accuracy: 0.8664\n",
            "Epoch 122/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5542 - accuracy: 0.8627 - val_loss: 0.5585 - val_accuracy: 0.8692\n",
            "Epoch 123/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5605 - accuracy: 0.8621 - val_loss: 0.5314 - val_accuracy: 0.8769\n",
            "Epoch 124/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5543 - accuracy: 0.8637 - val_loss: 0.6147 - val_accuracy: 0.8546\n",
            "Epoch 125/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5540 - accuracy: 0.8627 - val_loss: 0.5781 - val_accuracy: 0.8651\n",
            "Epoch 126/300\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5514 - accuracy: 0.8641 - val_loss: 0.5570 - val_accuracy: 0.8683\n",
            "Epoch 127/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5565 - accuracy: 0.8623 - val_loss: 0.6449 - val_accuracy: 0.8505\n",
            "Epoch 128/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5472 - accuracy: 0.8650 - val_loss: 0.6269 - val_accuracy: 0.8522\n",
            "Epoch 129/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5518 - accuracy: 0.8646 - val_loss: 0.6122 - val_accuracy: 0.8579\n",
            "Epoch 130/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5554 - accuracy: 0.8643 - val_loss: 0.5196 - val_accuracy: 0.8797\n",
            "Epoch 131/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5544 - accuracy: 0.8638 - val_loss: 0.6140 - val_accuracy: 0.8570\n",
            "Epoch 132/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5527 - accuracy: 0.8627 - val_loss: 0.6515 - val_accuracy: 0.8451\n",
            "Epoch 133/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5495 - accuracy: 0.8636 - val_loss: 0.5454 - val_accuracy: 0.8740\n",
            "Epoch 134/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5528 - accuracy: 0.8646 - val_loss: 0.5414 - val_accuracy: 0.8771\n",
            "Epoch 135/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5527 - accuracy: 0.8633 - val_loss: 0.5681 - val_accuracy: 0.8679\n",
            "Epoch 136/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5508 - accuracy: 0.8624 - val_loss: 0.5855 - val_accuracy: 0.8656\n",
            "Epoch 137/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5480 - accuracy: 0.8658 - val_loss: 0.5407 - val_accuracy: 0.8740\n",
            "Epoch 138/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5480 - accuracy: 0.8657 - val_loss: 0.5723 - val_accuracy: 0.8670\n",
            "Epoch 139/300\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5530 - accuracy: 0.8634 - val_loss: 0.5691 - val_accuracy: 0.8665\n",
            "Epoch 140/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5511 - accuracy: 0.8640 - val_loss: 0.6056 - val_accuracy: 0.8558\n",
            "Epoch 141/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5490 - accuracy: 0.8656 - val_loss: 0.5864 - val_accuracy: 0.8647\n",
            "Epoch 142/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5488 - accuracy: 0.8651 - val_loss: 0.5598 - val_accuracy: 0.8692\n",
            "Epoch 143/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5496 - accuracy: 0.8635 - val_loss: 0.5165 - val_accuracy: 0.8805\n",
            "Epoch 144/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5483 - accuracy: 0.8656 - val_loss: 0.6379 - val_accuracy: 0.8467\n",
            "Epoch 145/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5539 - accuracy: 0.8633 - val_loss: 0.6198 - val_accuracy: 0.8561\n",
            "Epoch 146/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5519 - accuracy: 0.8631 - val_loss: 0.6511 - val_accuracy: 0.8409\n",
            "Epoch 147/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5455 - accuracy: 0.8675 - val_loss: 0.5467 - val_accuracy: 0.8752\n",
            "Epoch 148/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5507 - accuracy: 0.8630 - val_loss: 0.6187 - val_accuracy: 0.8492\n",
            "Epoch 149/300\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5437 - accuracy: 0.8674 - val_loss: 0.5719 - val_accuracy: 0.8658\n",
            "Epoch 150/300\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5444 - accuracy: 0.8664 - val_loss: 0.5640 - val_accuracy: 0.8674\n",
            "Epoch 151/300\n",
            "316/781 [===========>..................] - ETA: 14s - loss: 0.5360 - accuracy: 0.8691Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Voj9szFp4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "33fa9e9b-dfcd-457e-bf65-dce923e96fdc"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('Result with 300 epochs, lr=0.001, decay=1e-6 :')\n",
        "print('Test loss', scores[0])\n",
        "print('Test accuracy', scores[1]*100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 64us/step\n",
            "Test loss 0.46630742025375366\n",
            "Test accuracy 88.41999769210815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKe8s-C-4zil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "543c1836-9a19-46c4-c38e-ca9f22ad04a4"
      },
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.0005,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep100.h5')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4843 - accuracy: 0.8843 - val_loss: 0.4774 - val_accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4686 - accuracy: 0.8884 - val_loss: 0.5312 - val_accuracy: 0.8766\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4658 - accuracy: 0.8904 - val_loss: 0.5202 - val_accuracy: 0.8795\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4665 - accuracy: 0.8898 - val_loss: 0.4843 - val_accuracy: 0.8863\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4560 - accuracy: 0.8907 - val_loss: 0.4800 - val_accuracy: 0.8864\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4545 - accuracy: 0.8925 - val_loss: 0.5372 - val_accuracy: 0.8760\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4534 - accuracy: 0.8895 - val_loss: 0.4979 - val_accuracy: 0.8841\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4531 - accuracy: 0.8901 - val_loss: 0.4946 - val_accuracy: 0.8851\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4489 - accuracy: 0.8905 - val_loss: 0.5006 - val_accuracy: 0.8877\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4522 - accuracy: 0.8900 - val_loss: 0.4739 - val_accuracy: 0.8917\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4490 - accuracy: 0.8904 - val_loss: 0.4833 - val_accuracy: 0.8847\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4445 - accuracy: 0.8925 - val_loss: 0.5342 - val_accuracy: 0.8778\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4444 - accuracy: 0.8904 - val_loss: 0.4878 - val_accuracy: 0.8864\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4384 - accuracy: 0.8929 - val_loss: 0.5189 - val_accuracy: 0.8783\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4400 - accuracy: 0.8913 - val_loss: 0.5110 - val_accuracy: 0.8790\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4406 - accuracy: 0.8923 - val_loss: 0.4818 - val_accuracy: 0.8848\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4409 - accuracy: 0.8925 - val_loss: 0.5126 - val_accuracy: 0.8764\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4350 - accuracy: 0.8943 - val_loss: 0.5210 - val_accuracy: 0.8753\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4373 - accuracy: 0.8945 - val_loss: 0.5111 - val_accuracy: 0.8769\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4386 - accuracy: 0.8928 - val_loss: 0.4782 - val_accuracy: 0.8875\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4334 - accuracy: 0.8943 - val_loss: 0.4947 - val_accuracy: 0.8788\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4340 - accuracy: 0.8926 - val_loss: 0.5333 - val_accuracy: 0.8714\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4349 - accuracy: 0.8919 - val_loss: 0.5314 - val_accuracy: 0.8752\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4359 - accuracy: 0.8922 - val_loss: 0.4869 - val_accuracy: 0.8878\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4295 - accuracy: 0.8939 - val_loss: 0.5203 - val_accuracy: 0.8789\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4300 - accuracy: 0.8924 - val_loss: 0.5019 - val_accuracy: 0.8796\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4300 - accuracy: 0.8940 - val_loss: 0.4869 - val_accuracy: 0.8843\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4308 - accuracy: 0.8941 - val_loss: 0.4905 - val_accuracy: 0.8840\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4300 - accuracy: 0.8938 - val_loss: 0.4616 - val_accuracy: 0.8896\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4320 - accuracy: 0.8928 - val_loss: 0.4706 - val_accuracy: 0.8886\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4271 - accuracy: 0.8952 - val_loss: 0.5153 - val_accuracy: 0.8776\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4250 - accuracy: 0.8955 - val_loss: 0.4620 - val_accuracy: 0.8904\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4347 - accuracy: 0.8907 - val_loss: 0.4805 - val_accuracy: 0.8842\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4259 - accuracy: 0.8940 - val_loss: 0.4907 - val_accuracy: 0.8819\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4267 - accuracy: 0.8940 - val_loss: 0.5320 - val_accuracy: 0.8744\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4254 - accuracy: 0.8931 - val_loss: 0.5100 - val_accuracy: 0.8779\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4267 - accuracy: 0.8927 - val_loss: 0.4918 - val_accuracy: 0.8822\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4229 - accuracy: 0.8938 - val_loss: 0.5293 - val_accuracy: 0.8756\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4280 - accuracy: 0.8945 - val_loss: 0.4479 - val_accuracy: 0.8957\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4277 - accuracy: 0.8931 - val_loss: 0.5038 - val_accuracy: 0.8790\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4257 - accuracy: 0.8927 - val_loss: 0.5134 - val_accuracy: 0.8759\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4222 - accuracy: 0.8949 - val_loss: 0.5087 - val_accuracy: 0.8822\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4245 - accuracy: 0.8941 - val_loss: 0.5323 - val_accuracy: 0.8709\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4267 - accuracy: 0.8935 - val_loss: 0.4949 - val_accuracy: 0.8763\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4271 - accuracy: 0.8944 - val_loss: 0.5296 - val_accuracy: 0.8743\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4231 - accuracy: 0.8935 - val_loss: 0.4968 - val_accuracy: 0.8770\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4197 - accuracy: 0.8964 - val_loss: 0.4945 - val_accuracy: 0.8860\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4255 - accuracy: 0.8936 - val_loss: 0.5238 - val_accuracy: 0.8707\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4221 - accuracy: 0.8956 - val_loss: 0.5111 - val_accuracy: 0.8788\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4211 - accuracy: 0.8936 - val_loss: 0.4948 - val_accuracy: 0.8821\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4269 - accuracy: 0.8945 - val_loss: 0.4672 - val_accuracy: 0.8869\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4258 - accuracy: 0.8933 - val_loss: 0.5730 - val_accuracy: 0.8634\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4225 - accuracy: 0.8955 - val_loss: 0.4902 - val_accuracy: 0.8800\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4215 - accuracy: 0.8940 - val_loss: 0.4943 - val_accuracy: 0.8793\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4247 - accuracy: 0.8928 - val_loss: 0.5249 - val_accuracy: 0.8778\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4262 - accuracy: 0.8941 - val_loss: 0.4711 - val_accuracy: 0.8856\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4200 - accuracy: 0.8943 - val_loss: 0.4723 - val_accuracy: 0.8887\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4207 - accuracy: 0.8955 - val_loss: 0.4754 - val_accuracy: 0.8859\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4222 - accuracy: 0.8954 - val_loss: 0.5016 - val_accuracy: 0.8783\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4169 - accuracy: 0.8977 - val_loss: 0.5104 - val_accuracy: 0.8741\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4171 - accuracy: 0.8954 - val_loss: 0.4866 - val_accuracy: 0.8832\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4230 - accuracy: 0.8939 - val_loss: 0.4484 - val_accuracy: 0.8911\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4173 - accuracy: 0.8952 - val_loss: 0.5538 - val_accuracy: 0.8650\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4232 - accuracy: 0.8933 - val_loss: 0.4815 - val_accuracy: 0.8817\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4193 - accuracy: 0.8948 - val_loss: 0.4962 - val_accuracy: 0.8775\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4225 - accuracy: 0.8936 - val_loss: 0.4920 - val_accuracy: 0.8805\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4215 - accuracy: 0.8955 - val_loss: 0.4692 - val_accuracy: 0.8883\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4204 - accuracy: 0.8959 - val_loss: 0.4559 - val_accuracy: 0.8883\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4103 - accuracy: 0.8982 - val_loss: 0.4984 - val_accuracy: 0.8818\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4188 - accuracy: 0.8958 - val_loss: 0.4930 - val_accuracy: 0.8819\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4175 - accuracy: 0.8963 - val_loss: 0.4728 - val_accuracy: 0.8837\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4212 - accuracy: 0.8949 - val_loss: 0.4821 - val_accuracy: 0.8819\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4188 - accuracy: 0.8952 - val_loss: 0.4789 - val_accuracy: 0.8874\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4204 - accuracy: 0.8947 - val_loss: 0.5225 - val_accuracy: 0.8768\n",
            "Epoch 75/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4146 - accuracy: 0.8955 - val_loss: 0.4920 - val_accuracy: 0.8832\n",
            "Epoch 76/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4188 - accuracy: 0.8945 - val_loss: 0.4636 - val_accuracy: 0.8914\n",
            "Epoch 77/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4186 - accuracy: 0.8953 - val_loss: 0.4958 - val_accuracy: 0.8777\n",
            "Epoch 78/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4162 - accuracy: 0.8957 - val_loss: 0.4823 - val_accuracy: 0.8845\n",
            "Epoch 79/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4226 - accuracy: 0.8942 - val_loss: 0.5099 - val_accuracy: 0.8764\n",
            "Epoch 80/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4212 - accuracy: 0.8938 - val_loss: 0.4775 - val_accuracy: 0.8860\n",
            "Epoch 81/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4170 - accuracy: 0.8957 - val_loss: 0.5035 - val_accuracy: 0.8790\n",
            "Epoch 82/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4163 - accuracy: 0.8961 - val_loss: 0.4837 - val_accuracy: 0.8850\n",
            "Epoch 83/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4165 - accuracy: 0.8973 - val_loss: 0.4718 - val_accuracy: 0.8866\n",
            "Epoch 84/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4176 - accuracy: 0.8947 - val_loss: 0.5128 - val_accuracy: 0.8798\n",
            "Epoch 85/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4191 - accuracy: 0.8945 - val_loss: 0.4689 - val_accuracy: 0.8877\n",
            "Epoch 86/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4160 - accuracy: 0.8952 - val_loss: 0.4504 - val_accuracy: 0.8937\n",
            "Epoch 87/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4181 - accuracy: 0.8957 - val_loss: 0.5227 - val_accuracy: 0.8731\n",
            "Epoch 88/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4123 - accuracy: 0.8967 - val_loss: 0.4768 - val_accuracy: 0.8914\n",
            "Epoch 89/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4176 - accuracy: 0.8954 - val_loss: 0.4894 - val_accuracy: 0.8860\n",
            "Epoch 90/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4163 - accuracy: 0.8960 - val_loss: 0.4757 - val_accuracy: 0.8848\n",
            "Epoch 91/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4170 - accuracy: 0.8960 - val_loss: 0.4819 - val_accuracy: 0.8809\n",
            "Epoch 92/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4154 - accuracy: 0.8957 - val_loss: 0.4900 - val_accuracy: 0.8793\n",
            "Epoch 93/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4175 - accuracy: 0.8959 - val_loss: 0.5034 - val_accuracy: 0.8810\n",
            "Epoch 94/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4141 - accuracy: 0.8963 - val_loss: 0.4742 - val_accuracy: 0.8883\n",
            "Epoch 95/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4161 - accuracy: 0.8956 - val_loss: 0.4993 - val_accuracy: 0.8827\n",
            "Epoch 96/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4150 - accuracy: 0.8945 - val_loss: 0.4618 - val_accuracy: 0.8883\n",
            "Epoch 97/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4139 - accuracy: 0.8963 - val_loss: 0.4924 - val_accuracy: 0.8813\n",
            "Epoch 98/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4159 - accuracy: 0.8952 - val_loss: 0.5305 - val_accuracy: 0.8696\n",
            "Epoch 99/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4155 - accuracy: 0.8965 - val_loss: 0.4902 - val_accuracy: 0.8798\n",
            "Epoch 100/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4091 - accuracy: 0.8978 - val_loss: 0.5347 - val_accuracy: 0.8698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRaH9tvKF1k6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e4ba6495-c8e0-47ba-ccf8-98d7fda03c7b"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('Result with 100 epochs, lr=0.0005, decay=1e-6 :')\n",
        "print('Test loss', scores[0])\n",
        "print('Test accuracy', scores[1]*100)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 69us/step\n",
            "Result with 100 epochs, lr=0.0005, decay=1e-6 :\n",
            "Test loss 0.46630742025375366\n",
            "Test accuracy 88.41999769210815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INKhcS-k4-iM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa749b9d-b1be-45cd-8c59-a4fe5589db12"
      },
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.0003,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep125.h5')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3932 - accuracy: 0.9026 - val_loss: 0.4687 - val_accuracy: 0.8893\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3897 - accuracy: 0.9026 - val_loss: 0.4585 - val_accuracy: 0.8874\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3845 - accuracy: 0.9060 - val_loss: 0.4811 - val_accuracy: 0.8826\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3838 - accuracy: 0.9068 - val_loss: 0.4648 - val_accuracy: 0.8861\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3827 - accuracy: 0.9043 - val_loss: 0.4655 - val_accuracy: 0.8862\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3829 - accuracy: 0.9067 - val_loss: 0.4688 - val_accuracy: 0.8895\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3769 - accuracy: 0.9048 - val_loss: 0.4480 - val_accuracy: 0.8929\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3786 - accuracy: 0.9064 - val_loss: 0.4452 - val_accuracy: 0.8948\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3767 - accuracy: 0.9081 - val_loss: 0.4462 - val_accuracy: 0.8929\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3752 - accuracy: 0.9080 - val_loss: 0.4647 - val_accuracy: 0.8886\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3725 - accuracy: 0.9079 - val_loss: 0.4575 - val_accuracy: 0.8895\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3699 - accuracy: 0.9087 - val_loss: 0.4615 - val_accuracy: 0.8894\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3698 - accuracy: 0.9078 - val_loss: 0.4427 - val_accuracy: 0.8946\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3656 - accuracy: 0.9076 - val_loss: 0.4722 - val_accuracy: 0.8886\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3701 - accuracy: 0.9076 - val_loss: 0.4249 - val_accuracy: 0.8971\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3722 - accuracy: 0.9071 - val_loss: 0.4631 - val_accuracy: 0.8898\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3661 - accuracy: 0.9085 - val_loss: 0.4800 - val_accuracy: 0.8829\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3717 - accuracy: 0.9067 - val_loss: 0.4568 - val_accuracy: 0.8884\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3634 - accuracy: 0.9075 - val_loss: 0.4777 - val_accuracy: 0.8844\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3691 - accuracy: 0.9086 - val_loss: 0.4469 - val_accuracy: 0.8941\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3684 - accuracy: 0.9063 - val_loss: 0.4300 - val_accuracy: 0.8953\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3662 - accuracy: 0.9079 - val_loss: 0.4399 - val_accuracy: 0.8940\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3642 - accuracy: 0.9084 - val_loss: 0.4371 - val_accuracy: 0.8934\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3673 - accuracy: 0.9093 - val_loss: 0.4295 - val_accuracy: 0.8972\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3645 - accuracy: 0.9071 - val_loss: 0.4305 - val_accuracy: 0.8970\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3648 - accuracy: 0.9084 - val_loss: 0.4359 - val_accuracy: 0.8944\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3635 - accuracy: 0.9086 - val_loss: 0.4564 - val_accuracy: 0.8923\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3662 - accuracy: 0.9085 - val_loss: 0.4386 - val_accuracy: 0.8923\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3614 - accuracy: 0.9084 - val_loss: 0.4492 - val_accuracy: 0.8893\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3628 - accuracy: 0.9075 - val_loss: 0.4334 - val_accuracy: 0.8950\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3599 - accuracy: 0.9095 - val_loss: 0.4616 - val_accuracy: 0.8904\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3586 - accuracy: 0.9103 - val_loss: 0.4740 - val_accuracy: 0.8833\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3592 - accuracy: 0.9082 - val_loss: 0.4493 - val_accuracy: 0.8919\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3646 - accuracy: 0.9087 - val_loss: 0.4395 - val_accuracy: 0.8891\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3645 - accuracy: 0.9073 - val_loss: 0.4419 - val_accuracy: 0.8902\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3604 - accuracy: 0.9093 - val_loss: 0.4606 - val_accuracy: 0.8891\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3560 - accuracy: 0.9110 - val_loss: 0.4542 - val_accuracy: 0.8882\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3624 - accuracy: 0.9076 - val_loss: 0.4568 - val_accuracy: 0.8869\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3601 - accuracy: 0.9092 - val_loss: 0.4787 - val_accuracy: 0.8856\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3556 - accuracy: 0.9108 - val_loss: 0.4822 - val_accuracy: 0.8847\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3561 - accuracy: 0.9092 - val_loss: 0.4632 - val_accuracy: 0.8876\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3537 - accuracy: 0.9103 - val_loss: 0.4508 - val_accuracy: 0.8902\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3654 - accuracy: 0.9083 - val_loss: 0.4540 - val_accuracy: 0.8915\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3541 - accuracy: 0.9098 - val_loss: 0.4218 - val_accuracy: 0.8992\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3570 - accuracy: 0.9086 - val_loss: 0.4454 - val_accuracy: 0.8910\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3550 - accuracy: 0.9105 - val_loss: 0.4477 - val_accuracy: 0.8926\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3572 - accuracy: 0.9100 - val_loss: 0.4583 - val_accuracy: 0.8889\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3540 - accuracy: 0.9097 - val_loss: 0.5038 - val_accuracy: 0.8790\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3584 - accuracy: 0.9090 - val_loss: 0.4601 - val_accuracy: 0.8877\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3562 - accuracy: 0.9077 - val_loss: 0.4634 - val_accuracy: 0.8886\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3472 - accuracy: 0.9122 - val_loss: 0.4551 - val_accuracy: 0.8913\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3563 - accuracy: 0.9099 - val_loss: 0.4306 - val_accuracy: 0.8979\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3526 - accuracy: 0.9107 - val_loss: 0.4474 - val_accuracy: 0.8910\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3568 - accuracy: 0.9098 - val_loss: 0.4141 - val_accuracy: 0.8977\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3515 - accuracy: 0.9104 - val_loss: 0.4510 - val_accuracy: 0.8894\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3482 - accuracy: 0.9122 - val_loss: 0.4458 - val_accuracy: 0.8938\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3588 - accuracy: 0.9079 - val_loss: 0.4300 - val_accuracy: 0.8946\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3539 - accuracy: 0.9113 - val_loss: 0.4405 - val_accuracy: 0.8907\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3538 - accuracy: 0.9093 - val_loss: 0.4655 - val_accuracy: 0.8890\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3550 - accuracy: 0.9093 - val_loss: 0.4504 - val_accuracy: 0.8881\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3528 - accuracy: 0.9103 - val_loss: 0.4209 - val_accuracy: 0.8988\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3565 - accuracy: 0.9096 - val_loss: 0.4376 - val_accuracy: 0.8918\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3550 - accuracy: 0.9093 - val_loss: 0.4406 - val_accuracy: 0.8936\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3535 - accuracy: 0.9100 - val_loss: 0.4634 - val_accuracy: 0.8876\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3483 - accuracy: 0.9121 - val_loss: 0.4152 - val_accuracy: 0.8975\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3551 - accuracy: 0.9086 - val_loss: 0.4207 - val_accuracy: 0.8989\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3494 - accuracy: 0.9114 - val_loss: 0.4378 - val_accuracy: 0.8915\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3537 - accuracy: 0.9099 - val_loss: 0.4402 - val_accuracy: 0.8884\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3490 - accuracy: 0.9107 - val_loss: 0.4410 - val_accuracy: 0.8913\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3506 - accuracy: 0.9103 - val_loss: 0.4716 - val_accuracy: 0.8846\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3511 - accuracy: 0.9100 - val_loss: 0.4261 - val_accuracy: 0.8963\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3495 - accuracy: 0.9109 - val_loss: 0.4266 - val_accuracy: 0.8912\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3518 - accuracy: 0.9095 - val_loss: 0.4506 - val_accuracy: 0.8852\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3548 - accuracy: 0.9088 - val_loss: 0.4538 - val_accuracy: 0.8869\n",
            "Epoch 75/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3490 - accuracy: 0.9115 - val_loss: 0.4366 - val_accuracy: 0.8956\n",
            "Epoch 76/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3503 - accuracy: 0.9102 - val_loss: 0.4419 - val_accuracy: 0.8923\n",
            "Epoch 77/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3434 - accuracy: 0.9120 - val_loss: 0.4564 - val_accuracy: 0.8855\n",
            "Epoch 78/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3527 - accuracy: 0.9083 - val_loss: 0.4573 - val_accuracy: 0.8858\n",
            "Epoch 79/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3506 - accuracy: 0.9109 - val_loss: 0.4733 - val_accuracy: 0.8842\n",
            "Epoch 80/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3526 - accuracy: 0.9102 - val_loss: 0.4519 - val_accuracy: 0.8887\n",
            "Epoch 81/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3477 - accuracy: 0.9117 - val_loss: 0.4245 - val_accuracy: 0.8980\n",
            "Epoch 82/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3497 - accuracy: 0.9112 - val_loss: 0.4758 - val_accuracy: 0.8831\n",
            "Epoch 83/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3490 - accuracy: 0.9117 - val_loss: 0.4447 - val_accuracy: 0.8887\n",
            "Epoch 84/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3503 - accuracy: 0.9097 - val_loss: 0.4271 - val_accuracy: 0.8951\n",
            "Epoch 85/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3461 - accuracy: 0.9101 - val_loss: 0.4880 - val_accuracy: 0.8829\n",
            "Epoch 86/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3520 - accuracy: 0.9095 - val_loss: 0.4295 - val_accuracy: 0.8961\n",
            "Epoch 87/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3528 - accuracy: 0.9084 - val_loss: 0.5010 - val_accuracy: 0.8781\n",
            "Epoch 88/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3493 - accuracy: 0.9095 - val_loss: 0.4373 - val_accuracy: 0.8929\n",
            "Epoch 89/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3505 - accuracy: 0.9090 - val_loss: 0.4435 - val_accuracy: 0.8902\n",
            "Epoch 90/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3488 - accuracy: 0.9115 - val_loss: 0.4422 - val_accuracy: 0.8882\n",
            "Epoch 91/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3477 - accuracy: 0.9103 - val_loss: 0.4320 - val_accuracy: 0.8928\n",
            "Epoch 92/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3458 - accuracy: 0.9106 - val_loss: 0.3987 - val_accuracy: 0.9000\n",
            "Epoch 93/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3487 - accuracy: 0.9109 - val_loss: 0.4089 - val_accuracy: 0.8975\n",
            "Epoch 94/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3499 - accuracy: 0.9096 - val_loss: 0.4706 - val_accuracy: 0.8878\n",
            "Epoch 95/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3488 - accuracy: 0.9111 - val_loss: 0.4675 - val_accuracy: 0.8841\n",
            "Epoch 96/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3521 - accuracy: 0.9091 - val_loss: 0.4274 - val_accuracy: 0.8924\n",
            "Epoch 97/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3430 - accuracy: 0.9113 - val_loss: 0.4433 - val_accuracy: 0.8936\n",
            "Epoch 98/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3505 - accuracy: 0.9095 - val_loss: 0.4552 - val_accuracy: 0.8902\n",
            "Epoch 99/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.3489 - accuracy: 0.9109 - val_loss: 0.4369 - val_accuracy: 0.8928\n",
            "Epoch 100/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.3504 - accuracy: 0.9103 - val_loss: 0.4663 - val_accuracy: 0.8842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HZbNaY24-Xe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b712e11b-b42f-4b82-cf2c-38efe36dc6f5"
      },
      "source": [
        "#testing - no kaggle eval\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('Result with 100 epochs, lr=0.0003, decay=1e-6 : ')\n",
        "print('Test loss', scores[0])\n",
        "print('Test accuracy', scores[1]*100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 66us/step\n",
            "Result with 100 epochs, lr=0.0003, decay=1e-6 : \n",
            "Test loss 0.46630742025375366\n",
            "Test accuracy 88.41999769210815\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}